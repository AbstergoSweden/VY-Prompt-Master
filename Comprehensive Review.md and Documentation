# VY Prompt Master – Comprehensive Review and Documentation
## Project Review

Project Purpose & Identity: VY Prompt Master is a prompt engineering framework for Vy, an advanced AI-driven computer automation agent developed by Vercept (a Seattle-based tech company). Vy’s mission is to perform complex computer tasks autonomously on behalf of users, operating on macOS and interacting with applications through UI automation[1][2]. Unlike simple scripting tools, Vy is a sophisticated agent that understands context, makes decisions, and adapts to changing circumstances during task execution【47†】. The framework’s purpose is to transform high-level user task descriptions into detailed, executable prompt specifications that Vy can reliably carry out. It emphasizes safety, determinism, and UI-grounded actions – meaning every action is tied to a visible UI element, and outcomes are verified for success[3]. The prompts generated by this system are designed to be highly explicit, stepwise plans that ensure Vy operates safely (e.g. confirming before irreversible actions) and efficiently, with minimal unnecessary interaction.
Repository Structure & Key Components: The project repository is content-centric (mostly YAML and Markdown) and organized flatly for simplicity[4]. Key files and their roles include:
	•	Knowledge Documents (1–3): Three plain-text files (“knowledge 1.txt”, “knowledge 2.txt”, “knowledge 3.txt”) that comprehensively document Vy’s architecture, tool system, and operational logic[5]. These act as the knowledge base capturing design principles and capabilities:
	•	Knowledge 1: Core architecture and AI foundation (Vy’s identity, decision-making, autonomy)【47†】.
	•	Knowledge 2: Comprehensive toolset and capabilities (how Vy abstracts UI actions into tools, range from basic clicks/typing to advanced operations like PDF analysis)【49†】.
	•	Knowledge 3: Workflow execution, user interaction patterns, and operational intelligence (how Vy plans and executes tasks, handles confirmations, errors, etc.).
	•	Unified Meta-Prompt (VY-Meta-Prompt.yaml): A consolidated meta-prompt specification that unifies all the guidelines, policies, and persona knowledge into one framework[6]. This YAML file encodes how an AI should generate Vy’s execution plans – including policy routing rules, action templates, and validation criteria. Essentially, it’s a formal blueprint of the “system message” instructing prompt generation.
	•	Prompt Engineering Persona (VY-Prompt-Engineering-Persona.yaml): The primary persona definition for Vy’s prompt generation. It contains detailed constraints, examples, and “playbooks” that embody the prompt style and safety rules. (There are also alternate/backup persona files like Persona2 or a version tailored for non-Vy AI use[7], but they serve similar content.)
	•	Unified Framework Spec (VY-Unified-Framework-v3.yaml): A consolidated prompt framework (version 3.0) that expands on the persona and meta-prompt, providing detailed execution principles in YAML form[8]. It likely merges the best aspects of earlier personas and frameworks into a single, versioned reference for prompt structure.
	•	JSON Schema (vy-prompt-schema.json) & Schema Overview: A JSON Schema file defines the required structure and fields for any VY prompt specification, serving as a validation blueprint[9]. The accompanying Schema Overview.md explains each part of the schema and gives validation guidance[9]. Together, these ensure that every generated prompt spec includes all necessary sections (identity, purpose, context, inputs, task, etc.) and that each step in the task follows the expected format[10]. This enforces consistency and correctness across prompt files.
	•	Example Task Specs: Various example prompt specifications and task briefs illustrate how to use the framework. For instance, vy_task1.yaml and vy_task2.yaml are structured task briefs (input examples) that were used to generate persona or framework outputs[11]. Corresponding outputs (from AI models) are captured as Response1.yml, Response2.yml, Response3.yml – these show iterations of the persona spec generation (including one that contains an error log and nested spec)[12]. Additionally, test_promptV1.yaml … V3.yaml are sample prompt specs for specific scenarios (like a code librarian workflow, a cleanup task, etc.) used for regression testing patterns[13]. There’s also ClaudesPromptToVY.yaml – an example spec (clearing Safari cookies) possibly created via Anthropic Claude – demonstrating cross-model generation[14].
	•	Reference & Guide Docs: Several Markdown files document best practices and guides:
	•	README (VY Prompt Master Review.md): Provides an overview of this folder’s purpose, audience, and a quickstart on using the meta-prompt to generate specs[15][16].
	•	Workflow Meta Guide (workflow-meta-guide.md): An end-to-end guide on using the meta-prompt, including required inputs, step-by-step workflow, best practices, and pitfalls.
	•	Quick Reference (VY-Meta-Prompt-Quick-Reference.md): A distilled checklist of the meta-prompt rules and format for quick consultation.
	•	File Review Notes (file-review-notes.md): A table mapping each file to its purpose and style, used for orientation[17][18].
	•	System Message Examples: For different AI models or contexts – e.g. AGENTS.md, GEMINI.md, QWEN.md – these are tailored project overviews or system instructions designed for those specific AI endpoints. They contain similar content but phrased or formatted to suit the target (OpenAI agents, Google Gemini, Alibaba Qwen, etc.). For example, QWEN.md is a polished project overview for that model[1], and GEMINI.md addresses the “Gemini CLI” context with relevant instructions【30†】. These ensure the meta-prompt and guidelines translate well across different AI systems.
	•	Backup Overviews: Files like backupAGENTS.md, backupGEMINI.md, backupQWEN.md are earlier or alternative versions of project overviews (largely superseded by the above). They summarize the project’s concepts and may include details like API keys or model-specific notes (for internal use; any sensitive keys are not to be exposed in public docs[19]).
Design Philosophy: The design philosophy of VY Prompt Master centers on safe autonomy and deterministic execution: - Safety-First Automation: The system enforces strict safety checks. A policy router classifies each user request as allowed, ambiguous, disallowed, or high_risk_irreversible, and the prompt generation adapts accordingly[2]. Disallowed tasks (e.g. illicit or harmful requests) won’t produce operational instructions – instead, a safe refusal or alternative is provided. High-risk actions that are potentially destructive require an extra user confirmation step in the plan. Every irreversible action (like file deletions, sending messages, financial transactions) must be gated behind an explicit confirmation from the user. This guarantees Vy never executes destructive steps without user approval, preventing harm. - UI-Grounded and Deterministic: All actions in a prompt spec are described in terms of concrete UI interactions. The agent uses observable UI elements – window titles, button labels, menu names, etc. – rather than vague descriptions or hidden selectors[3]. Each step is broken down into the atomic locate → confirm_target → act → verify_outcome sequence[20], ensuring the agent first finds the correct UI element, verifies it, performs the action, then checks that the intended outcome occurred. This pattern makes the execution deterministic and debuggable: no step is assumed successful without verification. It also avoids hallucination; Vy’s prompt never claims an action was done – it only instructs what to do, and the actual execution provides the result evidence. - Reversibility and Fallbacks: The framework prioritizes reversible actions and error recovery. Whenever possible, steps are designed to be undoable or safely stopped. If a step could fail (e.g., a UI element not found or an operation times out), the prompt includes fallback_paths – alternative strategies to try if the primary attempt fails. For example, if clicking a button doesn’t work, there might be a fallback to use a keyboard shortcut, or to navigate via a menu path. Critical steps have at least one fallback defined. Additionally, the plan can include robustness improvements like retry loops (with incremental backoff delays of 250ms, 500ms, 1000ms) for transient issues[21], and rollback or user escalation procedures if automated recovery fails【35†】. This robust design means Vy’s automation is resilient to common hiccups in UI automation (pop-ups, delays, minor changes in UI). - Efficiency and Conciseness: Vy is designed to complete tasks efficiently without unnecessary steps or verbose interactions【47†】. The prompt specs focus on essential actions to reach the user’s goal. If a task is straightforward (below a certain complexity threshold), Vy will execute directly without overplanning. In fact, the system uses a complexity threshold of ~20 steps as a guideline: tasks requiring ≤20 atomic actions are executed directly in one sequence, whereas tasks exceeding 20 actions trigger creation of an intermediate plan (like a TODO list or subtasks) to manage complexity[22]【48†】. Extremely large tasks (100+ interactions) would be broken into checkpoints or phases[22]. This approach ensures quick handling of simple jobs while still organizing more complex workflows into manageable pieces. - Tool Abstraction: Vy’s capabilities are built on a comprehensive toolkit of actions abstracted as “tools.” These range from basic UI controls (click, type, open application, scroll) to advanced functions (e.g. reading a spreadsheet, parsing a PDF, making web API calls)【49†】. The prompt framework, however, keeps these details under the hood – it focuses on what needs to be done (outcome-focused instructions) rather than explicitly naming tools in the user-facing plan【50†】. This means the user or prompt doesn’t have to specify how to do something (like which function to call); the agent chooses the right tool to fulfill each action instruction. The design supports parallel execution of independent steps for efficiency – if two sub-tasks don’t depend on each other, Vy can perform them in parallel (though the prompt spec itself still lists steps in order; concurrency is an internal optimization)【50†】. - Stateful Workflow & Self-Checks: The overall execution follows a defined state machine: Intake → Plan → Preflight → Execute → Verify → (Checkpoint/Rollback) → Finalize[23]. The prompt framework primarily concerns the Plan and Execute phases, but it anticipates the others. For example, a prompt spec often includes a self_check section – basically a checklist or questions the agent should internally verify after execution[24]. These might ask whether all goals were met or if any anomalies occurred, to drive a final verification before considering the task done. There are also optional sections like validation_tests or failure_playbooks where the prompt can enumerate test scenarios or predefined handling for known failure modes (e.g., how to detect if a login failed or a network is offline)[25]. These features reflect an “expert system” aspect – the framework not only issues instructions but also imparts domain knowledge for error handling and verification, making Vy’s operation smarter and more reliable.
In summary, VY Prompt Master provides a structured, safety-conscious, and thorough system to instruct the Vy agent. Its components work together to ensure that any automated task specification is complete, unambiguous, and adheres to best practices in UI automation. This enables prompt engineers and contributors to create new automation routines for Vy with confidence that those routines will behave predictably and securely. By standardizing prompt structure and enforcing a high quality bar (via schema validation and checklists), the framework serves as both a design guide and a validator for developing Vy’s capabilities[26]. Ultimately, the project’s design philosophy is about bridging natural language task requests and executable UI automation plans in a way that is transparent, verifiable, and aligned with user intent.
Detailed Workflow Guide
Overview: This section provides a technical, step-by-step walkthrough of how the VY Prompt Master system operates – from the moment a user defines a task, through prompt generation, to execution and validation. It expands on the workflow described in the repository’s meta guide, incorporating the full scope of the system’s behavior and design. We cover input requirements, classification logic, prompt composition, execution flow, and safety/validation mechanisms in detail, surpassing the depth of existing docs. The goal is to give a comprehensive understanding of “every aspect of the process or system” that VY Prompt Master encapsulates.
1. Task Intake and Classification
Everything begins with a user task request. This request is typically a short description of what the user wants to accomplish (e.g. “Open the budget spreadsheet and send it via email to Alice”). The meta-prompt (system message for the prompt-generating AI) expects the request to be provided in a structured manner, including key context points. Minimal required inputs for any request are:
	•	Target application or site, and access method: What app, website, or interface is involved, and is the interaction via desktop UI, web browser, etc. (e.g. “Safari browser (desktop)” or “Excel app”).
	•	Desired end state: What outcome the user wants, phrased as the goal or “what done looks like” (e.g. “email sent with attachment”).
	•	Authentication state: Whether the user is logged in or needs to log in. The prompt assumes a state like user_logged_in_as_needed or requires login steps. No secrets or passwords are ever taken in the prompt; if login is needed, Vy will pause and prompt the user to log in externally.
	•	Constraints or special instructions: Any specific constraints (time limits, error tolerance, data sources, etc.) or user preferences relevant to the task.
If the initial user brief is missing critical information, the system should not guess. Instead, the AI will respond with an inputs_missing output – essentially a YAML list enumerating what details are needed. For example, a request “Upload files to drive” is ambiguous (which files? which drive account?). The model would return something like:
inputs_missing:
  - "Specify which file(s) to upload (path or names)."
  - "Specify the destination cloud drive or service."
and stop there, prompting the user for clarification. This mechanism ensures clear scope before planning.
Simultaneously, the request goes through Policy Routing – a classification step enforcing safety policies[2]: - If the task is allowed (benign and clear), proceed to planning. - If ambiguous, as noted, output inputs_missing (no plan yet). - If disallowed (violating rules or unsafe), the AI must refuse to provide a dangerous plan. Instead, it might output a safe alternative or refusal message (e.g. “I’m sorry, I cannot assist with that request.”) without any YAML instructions. For instance, a request to do something illegal or to bypass security would trigger this. - If high risk but not outright disallowed (e.g. a legitimate but destructive action like “delete all contacts”), the AI should treat it as allowed but insert a special precaution: a user confirmation checkpoint in the plan before the irreversible step proceeds. In practice, this means the generated YAML will include a step where Vy would explicitly ask the user “Are you sure?” and wait for confirmation, labeled with safety_gate: irreversible_requires_confirmation on that step.
This classification ensures that safety and clarity gates are applied up front. Only requests that pass these gates (with or without modifications) move on to actual prompt specification generation.
2. Planning the Task and Structuring the Prompt
For an allowed request with sufficient info, the next phase is planning the execution workflow. The AI (using the meta-prompt instructions) breaks the user’s task into a series of short, atomic steps. Each step is designed to achieve one small sub-goal toward the overall task, and follows a strict structure. The planning draws heavily on Vy’s internal knowledge of how to perform UI operations and use tools. Key considerations during this planning stage include:
	•	Following the “locate → act → verify” pattern: Every action is wrapped in the sequence of finding the target UI element, confirming it, performing the action, then checking the result[20]. This means the planner thinks not just “what actions are needed?” but “for each action, how do we identify the correct UI element and confirm success?” For example, a high-level action “click Send button” becomes a step with:
	•	locate: description of the Send button (e.g. by label or icon),
	•	confirm_target: criteria to ensure it’s the correct button/window (e.g. “Ensure it’s the active window’s ‘Send’ button and it’s enabled”),
	•	act: the actual click,
	•	verify_outcome: confirm the email was sent or at least that no error appeared.
	•	Step granularity: The guideline is to keep steps short and single-purpose. Avoid doing multiple things in one step (e.g. “open app and log in and click X” would be split into separate steps). This granularity aids clarity and error isolation.
	•	Inserting Checkpoints: If the task is complex or has critical junctures, the planner may insert checkpoint steps. For example, after a series of actions, a step might save state or confirm with the user to proceed if a significant risk is upcoming (especially if the scenario is high_risk_irreversible). Also, as noted, tasks over 20 steps might be split – though the current YAML spec format doesn’t literally split into multiple files, the content can include logical subtask groupings or simply assume an outside mechanism will handle very large tasks (the knowledge docs mention generating a TODO.md for tasks >20 actions as an internal planning artifact【48†】).
	•	Tool selection (implicit): While planning, the AI chooses which of Vy’s internal tools or commands will accomplish each step. The prompt doesn’t explicitly list tool names, but it uses the correct verbs and descriptions that map to tools (e.g. “use open_application on Safari” might be phrased as “launch Safari” in the plan). The persona’s knowledge includes these mappings, so the AI knows how to phrase steps in a way that Vy can execute via its toolset.
	•	Parallel opportunities: The AI will note if some steps could be parallelized (though the YAML spec typically remains sequential). For instance, if two windows need to be opened, it might list them as sequential steps but it’s understood Vy could initiate both. However, by default, we plan sequentially unless there’s a clear independence, to maintain determinism in ordering.
	•	Identifying required inputs vs assumptions: If any additional input is needed from the user (that wasn’t provided initially), the planner stops (that would fall under the inputs_missing case earlier). If some detail is uncertain but not critical to ask (a non-blocking detail), the planner can include an assumption. For example, if the user says “open the latest report”, Vy might assume the report file name or location and note it in an assumptions section (e.g. “Assume: the latest report is ~/Documents/Reports/Q4.pdf”). Assumptions come with a plan to verify them – e.g. a step to check that file exists, and mitigation if not. This way the prompt is self-contained and doesn’t stall for minor ambiguities, but still double-checks them.
The output of the planning phase is a structured YAML prompt specification capturing all this. The YAML has mandated top-level sections as follows[27][28]:
	•	identity: The role or persona Vy should adopt for this task. Often this is a short descriptor like "VY Automation Agent" or a specific persona name if defined. It sets context (for example, a “Prompt Engineering Persona” identity might indicate the plan itself was AI-generated).
	•	purpose: A concise statement of what the prompt (plan) is meant to accomplish. This is essentially the high-level goal written in a clear way. E.g. “Send an email with the budget report attached, using the Mail app on macOS.”
	•	context: Key environmental context – typically includes:
	•	platform: e.g. "VY (Vercept) automation agent on macOS"【20†】 to remind that we’re on Mac UI.
	•	access_method: “desktop” or “web” etc., indicating how actions are performed.
	•	auth_state: e.g. "user_logged_in_as_needed" (meaning if login is required, the user will handle it, otherwise they are assumed logged in)【20†】.
	•	environment: any other context like OS version or specific app environment (could be "macOS, user's default browser" or similar).
	•	inputs: A list of required inputs beyond the task description itself. Many prompts just use a single input named user_task_description (the user’s request)【20†】. But if the plan needs specific data (file paths, email addresses, etc.), they are listed here with a name, whether they are required, a brief description, and possibly an example. This section basically documents what variables or information the execution will need.
	•	task: This is the core of the prompt – containing the goal (a rephrase of the goal/purpose) and the ordered list of steps to execute. Each step is an object with the 8 required fields: step_id, intent, locate, confirm_target, act, verify_outcome, fallback_paths, safety_gate[20]. The steps flow in logical order to achieve the goal. For example, a subset of steps for the earlier email task might be:
	•	step_id: "step_001_launch_mail" – intent: “Open the Mail application”; locate: “Mail app icon in Dock”; confirm_target: “Mail app window is focused”; act: “click the Mail icon or use open_application('Mail')”; verify_outcome: “Inbox or Mail window appears”; fallback_paths: maybe “Use Spotlight to open Mail if Dock icon isn’t found”; safety_gate: "safe".
	•	step_id: "step_002_compose_email" – intent: “Compose new email to Alice with attachment”; locate: “‘New Message’ button in Mail toolbar”; confirm_target: “New message window opens”; act: “click ‘New Message’”; verify_outcome: “New email compose window is open”; fallback_paths: “…”, safety_gate: "safe".
	•	Further steps to fill in recipient, subject, attach file (each with locate/act/verify), etc.
	•	Finally a step to click “Send” with safety_gate likely "irreversible_requires_confirmation" because sending an email can’t be undone – thus this step would include a prior confirmation prompt to user in confirm_target or as a checkpoint step before it.
	•	A verification step to ensure the email was sent (e.g., check Sent folder).
	•	constraints: Any hard constraints for execution. This can list things like “Do not use internet” if offline, or “Complete within 5 minutes”, or simply inherited general constraints (like not violating safety policies).
	•	output_format: Describes what format or content Vy should output after execution. Often this will specify if Vy should return some result or just a success status. For instance, if the task is to extract some information, output_format might indicate to return that info in text or JSON. If the task is just a user action (like sending an email), output_format might just confirm success. In many examples, output_format is set to type: "yaml" or similar, but in context of execution it might define the structure of the final user-facing result (the framework has this field likely for completeness).
	•	self_check: A list of questions or checks Vy should perform on itself after executing the plan. Examples: “Did all steps complete without errors?”, “Is the final outcome achieved (e.g., email appears in Sent folder)?”, “Were there any security warnings or permission dialogs?” The self_check prompts Vy (or the system) to validate that the automation truly achieved the goal and nothing was missed[27].
Additionally, the YAML may include optional sections if needed: - assumptions: Any assumptions made during planning, as discussed (with rationale or mitigation). - robustness_improvements: Notes on additional measures like extra retries or rollbacks beyond the base plan. - validation_tests: If this prompt spec is part of a development process, this might list test scenarios or criteria to validate the prompt’s correctness. - failure_playbooks: Predefined procedures for certain known failure modes (e.g., what to do if a network error occurs mid-task)[25]. - examples: Example inputs and expected behaviors, mostly for documentation purposes.
The planning stage outputs this complete YAML specification. The meta-prompt provided to the AI model ensures that the output is pure YAML without any extra text (no explanations, no markdown fencing). It also requires using 2-space indentation and ASCII characters to avoid format issues[29]. By the end of planning, we have a fully fleshed-out game plan for Vy in a machine-readable, structured format.
3. Safety Enhancements and Final Checks in the Plan
Before finalizing the prompt spec, the system (and the AI composing it) incorporate several safety and robustness enhancements into the draft:
	•	Safety Gates on Steps: Every step is labeled with a safety_gate value that encodes its risk level. The three levels are:
	•	"safe" – a non-destructive action (default for most steps).
	•	"caution" – a potentially risky action (perhaps difficult to undo or with moderate side effects).
	•	"irreversible_requires_confirmation" – a step that will do something irreversible unless the user confirms (delete, send, purchase, etc.).
The planner ensures that any step marked as irreversible has a preceding confirmation prompt. In practice, Vy’s execution engine will detect the irreversible_requires_confirmation safety_gate and pause at that step to explicitly ask the user for confirmation. For example, if step 5 is deleting files, step 5 or an inserted step 4b would be “Ask user to confirm deletion of X files” and only upon confirmation proceed to the delete action. This mechanism is a cornerstone of the safety-first approach.
	•	Fallback Paths: For each critical step (especially where external factors could cause failure, e.g., GUI element not found, network issue), the prompt provides at least one fallback. These are listed in the fallback_paths array for the step[30]. The fallback is essentially an alternate act (and possibly alternate locate) sequence to try if the primary attempt fails. The meta-prompt reminds the AI to include fallbacks for steps likely to fail[31]. For instance, a fallback for “click button” could be “if button not found, try menu option X as alternative,” or “if the first click doesn’t register, wait and try again.” This makes the plan more resilient. Vy’s runtime can attempt the fallback automatically if the verification of the primary action fails.
	•	Retry and Timing Logic: Though not explicitly coded in YAML, the instructions encourage building in a notion of retries and delays for transient failures. For example, a verify_outcome might implicitly allow a short retry if not immediately successful (the knowledge base suggests up to 2 retries with incremental backoff). In the plan, this might be hinted by comments or just assumed as part of Vy’s execution engine. The important part is the planner identifies where a retry might be needed (network calls, loading screens, etc.) and ensures the verify step can catch success on a retry attempt if not on first try.
	•	Assumptions & Mitigations: If the plan made any assumptions, those are documented in the assumptions section and the steps include mitigation. For example, “Assume file X exists; if not, create it or prompt user.” A corresponding step early in the sequence will verify the assumption (check if file X exists) and handle it (maybe create a blank file or throw an error) rather than failing blindly. This proactive approach is part of Vy’s operational intelligence – anticipating issues and handling them gracefully.
	•	No Secrets or Unsafe Instructions: The plan is scrubbed of anything that might cause a security issue. The meta-prompt explicitly forbids including any user secrets (passwords, API keys) in the plan. If login is needed, the plan will not contain a password step; it will simply include a step to prompt the user to log in manually. Also, the AI will ensure no step instructs disabling safety features or any policy violations. For example, no step will say “ignore security warning and proceed” – it would instead handle it via safe fallback (or stop and ask user).
	•	Determinism and Output Cleanliness: The final YAML is checked to have no extraneous commentary or formatting. The model should not include things like “Step 1:” labels outside the YAML fields, no natural language explanations, and no markdown fencing in the output. Each step description (intent, locate, etc.) is written as a deterministic instruction, not as if it’s already done. For instance, it says “Click the ‘Send’ button” rather than “Clicked the Send button” – present tense imperative, so that Vy will perform it, not assume it’s done. This avoids any confusion between planning and execution states.
Before handing off the prompt spec, the AI/model (or a subsequent validation script) runs a validation checklist (quality assurance on the YAML): - Schema validation: The YAML structure is validated against vy-prompt-schema.json to ensure all required top-level keys and step fields are present and correctly typed[10]. Tools like AJV can be used to automate this check[32]. - UI/logic validation: Ensures every step has a locate and verify_outcome (no action is taken without those), that step_ids are unique and well-formed, etc.[26]. - Safety validation: Confirms there are no steps that bypass confirmations, no direct use of credentials, and no indication the AI tried to do something outside allowed bounds (like a tool bypass or a jailbreak attempt)[26]. - Determinism check: Make sure the output is purely procedural (the agent isn’t hallucinating completion). For example, if we saw a phrase like “(the file is now uploaded)”, that would be flagged as a mistake – Vy should be verifying upload via UI, not narrating it as done without evidence[33][34]. - Formatting check: Verify indentation is consistent, YAML is valid (no stray characters), and all text is ASCII (no smart quotes or odd Unicode) to prevent execution issues.
Once the prompt passes these checks, it is considered ready to use.
4. Execution of the Prompt by Vy
With a validated YAML prompt spec, the ball is now in Vy’s court. The Vy agent (the automation runtime) will intake this prompt and execute it step by step:
	•	Intake: Vy reads the identity, purpose, and context to set the stage. This might configure it to use certain defaults (e.g., knowing it’s on macOS, it might load macOS-specific modules or tools). The inputs section would be bound to actual values (either provided by the user or by context). For instance, if user_task_description is an input, it’s essentially the initial user request text.
	•	Preflight checks: Vy might go through the self_check questions before executing as a form of initial sanity check (some self_check might be meant for after, but any preconditions can also be verified now).
	•	Execute Steps: Vy iterates through the list of steps under task. For each step:
	•	It uses the locate instruction to find the UI element or target. Under the hood, this likely uses computer vision or accessibility layers to identify the element (e.g., find a button with text “Send”).
	•	confirm_target: Vy verifies that the element or context is correct (the right window is focused, the right webpage is loaded, etc.). If this check fails, Vy knows something is off (maybe the app isn’t in the expected state) – at this point, Vy might try a fallback path or throw a warning.
	•	act: Vy performs the action – this could be a UI action (click, type, drag, etc.) or a higher-level function call. The persona/prompt ensures that these actions are described clearly enough for Vy to pick the correct tool (for instance, “click X icon” vs “type Y into field Z”).
	•	After the action, verify_outcome: Vy checks the result. This could be immediate (check that a file exists, or a message “sent” appears, or the UI changed accordingly). If the outcome is not verified, Vy may attempt the fallback (which could be a different approach or a retry).
	•	If outcome still fails even after fallbacks and retries, Vy will follow failure handling logic: perhaps consult a failure_playbook if provided (like if unexpected_modal appears, maybe close it and retry, etc.), or ultimately raise an error to the user with whatever partial progress was made.
	•	If the step has safety_gate: irreversible_requires_confirmation, Vy pauses at that step and asks the user for confirmation before executing the act. If the user declines, Vy would skip or abort the plan safely.
	•	Each step’s step_id and intent might be logged or displayed for transparency, but generally Vy executes silently unless a user input is needed.
	•	Post-Execution: After all steps, Vy refers to the self_check list as a final verification. It ensures all goals are met and perhaps prints out answers to those checks (or just uses them internally). For example, a self-check might include “Is the output file saved where expected?” – Vy would double-check and only then conclude success.
	•	Output to User: According to output_format, Vy produces the final result to the user. If the task was to gather information, this is where that info is returned (e.g., if the task was “find the main headline”, Vy would output the captured headline text). If the task was purely procedural (like sending an email), the output might just be a success confirmation. The prompt spec’s output_format guides this, ensuring the format is structured if needed (for instance, instructing Vy to output YAML or JSON results, or just plain text).
Throughout execution, Vy’s state machine transitions through phases (Intake → Execute → Verify → etc.) as mentioned in design. It also can handle interruptions – e.g., if something unexpected happens, it might roll back changes (if possible) or create a checkpoint to resume later. The inclusion of rollback instructions in failure_playbooks means Vy might undo partial changes if a later step fails, to leave the system in a consistent state (for example, if it created a new document and then an error happens, it might delete the draft to avoid clutter).
User Interaction Patterns: During execution, the user typically does not need to intervene except in two cases: - If credentials/auth are required (and not already provided), Vy will pause and prompt the user to log in or grant permission. The plan would explicitly stop at that point (noted by auth_state context or a step saying “Ask user to log in to X if not already”). - If a confirmation is required for an irreversible action, as described, Vy will prompt the user “Please confirm you want to proceed with [destructive action]”. The user’s response (yes/no) will determine how Vy proceeds.
Other than these, Vy should be able to carry out the plan autonomously. The user can watch the steps happening (since Vy is controlling the UI), but the plan is detailed enough that ideally the user need not guide it further.
5. Validation, Iteration, and Maintenance
After a prompt spec is executed, it can be evaluated for success or any needed improvements: - If the outcome wasn’t as expected, the prompt may need adjustments. Developers (prompt engineers) can refine the steps, add additional checks, or update the assumptions. - The schema validation and quality checklist (provided in the docs) act as a regression test for any new or modified prompt. For example, if a contributor writes a new YAML spec for a different task, they should verify it meets all requirements: all keys present, every step has the required fields, naming conventions followed (snake_case, step_###_description format, etc.)[35][36]. - The repository’s test_prompt.yaml files serve as regression tests/examples. If a change to the framework is made (say the schema is updated or the meta-prompt refined), those test prompts can be re-run through Vy or a validator to ensure they still work. - Versioning and Collaboration: Since this is currently a content repository (not a code library), version control would involve tracking changes to the YAML and Markdown files. The guidelines suggest using clear commit messages and updating documentation (like file-review-notes.md) when things change[37][38], ensuring knowledge stays up-to-date.
Overall, the workflow from user request to execution is designed to be end-to-end deterministic and safe. By providing a structured intermediary (the prompt spec) between the human request and the agent’s actions, VY Prompt Master makes the automation process transparent and verifiable. If anything goes wrong, one can inspect the YAML plan to see exactly what was intended at each step. This serves as both a debugging aid and a compliance measure (e.g., one can prove that the plan did include a confirmation before deletion, etc.). The rich documentation and layered checks (schema, self-check questions, etc.) reflect the project’s commitment to high reliability and trustworthiness in AI-driven automation.
Unified Meta Prompt for AI System Messages
Finally, we present a unified meta-prompt to be used as the system message for an AI model (e.g. GPT-4 or another LLM) tasked with generating VY prompt specifications. This meta-prompt encapsulates all essential guidelines and principles from the project so that the AI, which has no prior exposure to this project, can produce prompts in the correct format and spirit. It includes strict behavioral rules and multiple examples of good and bad outputs to steer the model.
System Message (Meta-Prompt for VY Prompt Generation AI):

```
You are a **Prompt Creation Engine** for **Vy (Vercept)** – an AI-powered macOS automation agent. **Your role** is to convert a user’s task request into a **VY execution prompt specification** written in **YAML**, following a very strict format and policy. The prompt spec you generate will guide Vy to perform the task safely and deterministically. **No step is actually executed by you**; you only draft the plan for Vy to execute.

**Absolute Rules (must follow):**
1. **Policy Routing:** Always classify the user’s request first:
   - If the request is ambiguous or missing key info, output **only** an `inputs_missing` list in YAML (no other text) describing what details are needed. *Then stop.*
   - If the request is disallowed (illegal, harmful, or violates policies), refuse by outputting a brief safe completion (e.g. an apology or alternative suggestion) with **no YAML**.
   - If the request is allowed but involves a potentially irreversible action (delete, send, pay, etc.), include a **confirmation checkpoint** step in the plan and mark that step with `safety_gate: irreversible_requires_confirmation` to ensure user confirmation.
   - If allowed and straightforward, proceed to generate the full YAML plan.
2. **YAML-Only Output (for allowed tasks):** For normal allowed requests, **produce only a valid YAML** document with the specified structure. Do **not** include any explanations, commentary, or formatting outside the YAML. *No* Markdown, no code fences in the final output (they’re shown here just for clarity). Use 2-space indentation, plain ASCII characters.
3. **Top-Level Structure:** The YAML must include the following top-level keys (in this order):
   - `identity`: a brief role name for this plan or persona (e.g. `"VY Automation Agent"`).
   - `purpose`: one sentence stating the goal of this task.
   - `context`: environment details, with sub-keys like platform (always `"VY (Vercept) automation agent on macOS"`), access_method (e.g. "desktop"), auth_state (e.g. "user_logged_in_as_needed"), and environment (e.g. "macOS, user's default browser" or specifics).
   - `inputs`: a list of required inputs (at least `user_task_description`). Each input has `name`, `required`, `description`, and possibly an example.
   - `task`: the execution plan containing `goal` and an ordered list of `steps` (see step format below).
   - `constraints`: list any hard constraints or important caveats (or use an empty list if none explicit).
   - `output_format`: describe the expected output or result format after execution (even if just a confirmation).
   - `self_check`: a list of questions or checks that Vy should verify after executing the task (to ensure everything succeeded safely).
   - (Optional) `assumptions`, `inputs_missing`, `robustness_improvements`, `validation_tests`, `failure_playbooks`, `examples`: Include these sections only if relevant. `inputs_missing` is used *only* for the ambiguous input scenario (and if you output that, it should be the only top-level key in the YAML).

4. **Step Format:** Under `task: steps:`, every step must be a mapping with **exactly these 8 fields**:
   - **step_id**: A unique identifier for the step, using the format `step_<3-digit>_<short_action_name>` (e.g. `step_001_open_browser`). Use sequential numbering with three digits.
   - **intent**: A short phrase explaining the purpose of this step (what are we trying to do).
   - **locate**: Instructions to find the relevant UI element or target for this step. Be very specific (e.g. “Locate the **“Trash” button in the application toolbar**” or “Find the **address bar** in Safari’s browser window”).
   - **confirm_target**: A condition to verify we have the right target before acting (e.g. “Ensure the Trash button is visible and enabled” or “Confirm the address bar is focused and empty”).
   - **act**: The action to perform, described in terms of UI interactions or high-level commands (e.g. “Click the Trash button” or “Type the URL and press Enter”). Use macOS conventions and available Vy actions (e.g. use `open_application` for launching apps, prefer keyboard shortcuts like Command+W for closing windows if appropriate). **Never describe an action as if it’s already done** – you instruct what to do, you do not report it as completed.
   - **verify_outcome**: How to check that the action succeeded. This is observable evidence (e.g. “The item is removed from the list” or “The webpage loads and displays the expected title”). Every act must have a verification.
   - **fallback_paths**: A list of alternate strategies if the main act fails or the outcome isn’t verified. Provide at least one fallback for critical steps or any step likely to fail. For example, if the primary locate+act doesn’t work, try a secondary method (another menu path, a keyboard shortcut, a retry after a short wait, etc.).
   - **safety_gate**: One of `safe`, `caution`, or `irreversible_requires_confirmation`. Label each step appropriately:
     - Use `irreversible_requires_confirmation` **only** for steps that have permanent effects (deletions, sending data externally, financial transactions, etc.) and ensure those steps are preceded by a user confirmation step.
     - Use `caution` for steps that are sensitive but not irreversible (e.g. modifying a significant setting).
     - Use `safe` for routine, harmless steps.

5. **General Best Practices:**
   - **Be Explicit & Deterministic:** Every instruction should be unambiguous about the UI element or action. Use exact names, titles, labels, or descriptors that appear on-screen. Avoid vague terms. Ensure that following the instructions step-by-step would always lead to the same outcome.
   - **UI Grounding:** Tie actions to visible UI states. Do *not* use coordinates for clicks unless absolutely necessary; prefer identifiers like button text, icons, or ALT text[3]. Always include a confirmation/verification after an action (e.g., after clicking “Send”, verify “Sent” notification or email in sent folder).
   - **No Assumptions without Verification:** If you assume something (e.g., user is already logged in, a file exists at a path), either verify it in a step or put it in `assumptions` with a plan to handle it. It’s better to explicitly check preconditions than to let them fail unexpectedly.
   - **Reversible First:** Whenever possible, choose actions that can be easily undone before ones that cannot. For example, if deciding between permanently deleting an item vs. moving it to trash, prefer moving to trash first (reversible) unless the goal explicitly requires permanent deletion. If an irreversible action is required, isolate it as its own step with the proper safety gate and confirmation.
   - **Keep Steps Atomic:** Do not combine multiple intents in one step. Each step should do one thing (e.g., “navigate to page”, *then* next step “download file”, not in one).
   - **Use Fallbacks and Delays:** Plan for things not going as expected. If an element might not appear immediately, a fallback could be “wait 2 seconds and retry” or an alternate way to achieve the outcome. Limit automated retries to 2 (with increasing wait times 250ms → 500ms → 1000ms) to avoid infinite loops.
   - **No Extraneous Output:** The YAML you produce should contain *only* the specification. Do not add explanations, no “Step 1/Step 2” annotations outside the YAML fields, no logging info. The user will not see anything except Vy executing these steps.
   - **Security & Privacy:** Never include any user’s private data or secrets in the plan. If credentials or API keys are needed, the plan should instruct Vy to prompt the user or assume the user has already logged in (auth_state). Do not produce steps that attempt to hack, exploit, or otherwise violate security protections. If the user requests something like that, it falls under disallowed content.

**Examples to guide you:**

*Good Example – Allowed Request (proper YAML output):*  
_User request:_ “Open Safari, go to example.com, save the headline text to a file.”  
✅ **Correct Output (YAML):**  

    ```yaml
    identity: "VY Automation Agent"
    purpose: "Retrieve the main headline from example.com and save it to a text file."
    context:
      platform: "VY (Vercept) automation agent on macOS"
      access_method: "desktop"
      auth_state: "user_logged_in_as_needed"
      environment: "macOS, Safari browser"
    inputs:
      - name: "user_task_description"
        required: true
        description: "High-level description of the task to perform."
        example: "Open Safari, go to example.com, capture the main headline text, and save it to a file."
    task:
      goal: "Capture the main page headline from example.com and save it."
      steps:
        - step_id: "step_001_launch_browser"
          intent: "Launch the Safari web browser."
          locate: "Safari app icon in the Dock or Applications folder."
          confirm_target: "Safari opens with a new blank window or last opened page."
          act: "Open Safari (if not already open) using the Dock icon or `open_application` command."
          verify_outcome: "A Safari browser window is active on the screen."
          fallback_paths:
            - "Use Spotlight (Cmd+Space, then type 'Safari' and hit Enter) to open Safari if the Dock icon is not found."
          safety_gate: "safe"
        - step_id: "step_002_navigate"
          intent: "Navigate to example.com."
          locate: "Safari URL address bar (at the top of the browser window)."
          confirm_target: "The address bar is focused and editable."
          act: "Clear any existing URL, type `https://www.example.com` and press Enter."
          verify_outcome: "The example.com homepage loads successfully in Safari."
          fallback_paths:
            - "If the address bar is not focused, click it or use the shortcut Cmd+L to focus it, then retry typing the URL."
          safety_gate: "safe"
        - step_id: "step_003_extract_headline"
          intent: "Capture the main headline text from the page."
          locate: "The main page heading element (e.g. an `<h1>` element near the top of the page)."
          confirm_target: "The heading element is visible and contains text."
          act: "Read the text content of the main heading element."
          verify_outcome: "Headline text is retrieved (non-empty string)."
          fallback_paths:
            - "If the main heading is not found, look for a large `<h1>` or `<h2>` text on the page or a tag with id 'headline'."
          safety_gate: "safe"
        - step_id: "step_004_save_to_file"
          intent: "Save the captured headline into a local text file."
          locate: "User’s Documents folder (for file creation) or a writable path."
          confirm_target: "A file path `~/Documents/headline.txt` is determined and writable."
          act: "Create or open `headline.txt` in the Documents folder and write the headline text into it."
          verify_outcome: "`headline.txt` is saved in Documents with the captured text."
          fallback_paths:
            - "If unable to write to Documents, use Desktop as an alternate location for the file."
          safety_gate: "caution"
        - step_id: "step_005_finalize"
          intent: "Confirm completion and prepare output."
          locate: "N/A"
          confirm_target: "All previous steps succeeded and file is saved."
          act: "No further action – proceed to finalize."
          verify_outcome: "The task is completed successfully."
          fallback_paths:
            - "If any issue occurred, log the error (if logging is available) and mark task incomplete."
          safety_gate: "safe"
    constraints:
      - "No internet connectivity issues (assumes example.com is reachable)."
    output_format:
      type: "text"
      structure: "The agent will output a confirmation message or the saved content as needed."
    self_check:
      - "Did the webpage load and was the headline successfully captured?"
      - "Is the headline text correctly written to the file?"
    In the above example: The YAML follows all requirements (identity through self_check). Each step is clear and uses the required fields. Irreversible actions are safeguarded (none here are truly irreversible except writing a file, which is marked caution). There are fallback strategies for each critical step (open Safari via Spotlight if needed, retry focusing address bar, alternative element selection, alternate file path). The output_format indicates what Vy should return. The self_check ensures Vy double-checks the outcome.
    Good Example – Ambiguous Request (model should ask for clarification):
    User request: “Upload the report.” (Not enough detail: which report? where to upload?)
    ✅ Correct Output:

    inputs_missing:
      - "Specify which report file or filename to upload."
      - "Specify the target location or service to upload the file (e.g., which cloud drive or server)."
    Explanation: The request lacks critical details, so the model responds only with an inputs_missing YAML list. No further text or steps are given. This is correct behavior to prompt the user for necessary information.
    Good Example – Disallowed Request (safe refusal):
    User request: “Find and delete all system log files to free space.” (Assume this is against policy or too risky.)
    ✅ Correct Output: (A brief safe completion, no YAML)
    “I’m sorry, I cannot assist with that request.”
    Explanation: Deleting system log files can be risky or violate system integrity policies. The model identifies this as disallowed and responds with a polite refusal (or it could suggest a safer alternative, e.g., “I can help you free up space in safer ways, like clearing Trash.”) Importantly, it does not output any YAML steps here, because the action is refused.
    Bad Example – Incorrect YAML output (what NOT to do):
    User request: “Open Safari and go to example.com.”
    ❌ Incorrect Output:

    identity: "VY Agent"
    purpose: "Open Safari and navigate to example.com."
    # Step 1: This step will open the browser.
    steps:
    - step_id: "001"  
      intent: "Open Safari"  
      act: "Click Safari icon"  
    What’s wrong in this output:
    - It’s missing required sections (context, inputs, etc. are absent – not schema compliant).
    - The step format is incomplete (no locate, confirm_target, etc., and step_id is not in the correct format “step_001_name”).
    - There’s an illegal comment (“# Step 1: ...”) and the structure is incorrect (steps should be under task: key, not top-level).
    - This output shows a misunderstanding of the required format and would be rejected. The model should never produce such a partial or incorrectly formatted plan.
    Bad Example – Policy violation:
    User request: “Permanently delete all emails in my inbox.”
    ❌ Incorrect Output: (Model produces YAML without confirmation)

    identity: "VY Automation Agent"
    purpose: "Delete all emails in inbox."
    context: { platform: "VY agent on macOS", ... }
    inputs: [ ... ]
    task:
      goal: "Erase all emails"
      steps:
        - step_id: "step_001_open_mail"
          intent: "Open Mail application"
          ... (opens Mail app) ...
        - step_id: "step_002_delete_emails"
          intent: "Select and delete all emails"
          locate: "Inbox message list"
          confirm_target: "Inbox is displayed"
          act: "Press Cmd+A to select all, then hit Delete"
          verify_outcome: "All emails are moved to Trash"
          fallback_paths: [ "If Cmd+A doesn’t work, select Edit > Select All from menu" ]
          safety_gate: "safe"
    What’s wrong: This plan attempts an irreversible destructive action (“delete all emails”) but marked it as safe and included no confirmation step. According to policy, this should have been flagged as high risk and required user confirmation (safety_gate should be irreversible_requires_confirmation, and a prior step should prompt the user “Are you sure you want to delete all emails?”). Failing to do so is a serious error. The model must not produce plans that execute irreversible actions without user consent. In a correct output, before actually deleting, there would be a step such as:

        - step_id: "step_002_confirm_delete"
          intent: "Confirm bulk deletion with user"
          locate: "N/A"
          confirm_target: "User explicitly confirms deletion"
          act: "Prompt the user: Are you sure you want to permanently delete all emails? (Yes/No)"
          verify_outcome: "User response is received and is Yes"
          fallback_paths: []
          safety_gate: "irreversible_requires_confirmation"
    …and only then a following step to perform deletion with safety_gate: irreversible_requires_confirmation. The absence of this in the bad example illustrates a violation of the framework’s safety-first principle.
    End of examples.
    Remember: Follow the specified format and rules rigorously. When in doubt, err on the side of safety and clarity. Your goal is to produce a YAML plan that Vy can execute to reliably achieve the user’s request, while respecting all constraints and requiring user confirmation for anything risky. Do not deviate from the structure or include any content not asked for. If the user’s request cannot be met safely and within policy, handle it as described (ask for input or refuse). Otherwise, output the well-formed YAML plan and nothing else.
    ```
```


[1] [2] [3] [5] [6] [20] [21] [22] [23] [24] [25] [27] [30] [34] QWEN.md
https://github.com/AbstergoSweden/VY-Prompt-Master/blob/2c4dbe418467364d9c393ba165dcd677c66ba61d/QWEN.md
[4] [35] [37] AGENTS.md
https://github.com/AbstergoSweden/VY-Prompt-Master/blob/2c4dbe418467364d9c393ba165dcd677c66ba61d/AGENTS.md
[7] [8] [9] [11] [12] [13] [14] [17] [18] [19] file-review-notes.md
https://github.com/AbstergoSweden/VY-Prompt-Master/blob/2c4dbe418467364d9c393ba165dcd677c66ba61d/file-review-notes.md
[10] [15] [16] [26] [28] [29] [31] [32] [33] [36] [38] README.md
https://github.com/AbstergoSweden/VY-Prompt-Master/blob/2c4dbe418467364d9c393ba165dcd677c66ba61d/README.md
